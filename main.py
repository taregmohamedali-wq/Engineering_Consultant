import streamlit as st
import pandas as pd
import fitz  # PyMuPDF
from g4f.client import Client
import g4f

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="AI Engineering Consultant", layout="wide")

# Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„Ù„ØºØ§Øª
text_content = {
    "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": {
        "title": "ğŸ—ï¸ Ø§Ù„Ù…Ø³ØªØ´Ø§Ø± Ø§Ù„Ù‡Ù†Ø¯Ø³ÙŠ Ø§Ù„Ø°ÙƒÙŠ",
        "sub": "ØªØ­Ù„ÙŠÙ„ ÙˆÙ…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…ÙˆØ§ØµÙØ§Øª Ø§Ù„ÙÙ†ÙŠØ© Ø¨Ù€ 6 Ø£Ø¹Ù…Ø¯Ø©",
        "spec_label": "Ù…Ù„Ù Ø§Ù„Ù…ÙˆØ§ØµÙØ§Øª (PDF)",
        "offer_label": "Ù…Ù„Ù Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ÙÙ†ÙŠ (PDF)",
        "btn": "Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ",
        "loading": "Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„... Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ Ø¯Ù‚ÙŠÙ‚Ø©",
        "result": "Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©",
        "sidebar_head": "Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª"
    },
    "English": {
        "title": "ğŸ—ï¸ Smart Engineering Consultant",
        "sub": "Technical Analysis & Comparison (6 Columns)",
        "spec_label": "Specifications File (PDF)",
        "offer_label": "Technical Offer File (PDF)",
        "btn": "Start Analysis",
        "loading": "Analyzing... please wait",
        "result": "Final Results",
        "sidebar_head": "Settings"
    }
}

# Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù„ØºØ© ÙÙŠ Ø§Ù„Ø£Ø¹Ù„Ù‰
selected_lang = st.radio("Language / Ø§Ù„Ù„ØºØ©", ["Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "English"], horizontal=True)
content = text_content[selected_lang]

st.title(content["title"])
st.subheader(content["sub"])

# Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª
col1, col2 = st.columns(2)
with col1:
    specs_file = st.file_uploader(content["spec_label"], type=['pdf'], key="specs")
with col2:
    offer_file = st.file_uploader(content["offer_label"], type=['pdf'], key="offer")

def extract_text(file):
    doc = fitz.open(stream=file.read(), filetype="pdf")
    return "".join([page.get_text() for page in doc])[:4000]

if st.button(content["btn"]):
    if specs_file and offer_file:
        with st.spinner(content["loading"]):
            try:
                specs_text = extract_text(specs_file)
                offer_text = extract_text(offer_file)

                client = Client()
                # ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ù„ÙŠØ¬Ø¨Ø± Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¹Ù„Ù‰ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù…ØªØ§Ø­
                prompt = f"""
                Act as a Senior Engineer. Compare:
                Specs: {specs_text}
                Offer: {offer_text}
                Return a table with 6 columns in {selected_lang}: 
                (Item, Required Specs, Provided Description, Status, Deviations, Consultant Note).
                """

                # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙˆØ¯ÙŠÙ„ ÙØ§Ø±Øº Ù„ÙŠØ¯Ø¹ Ø§Ù„Ù…ÙƒØªØ¨Ø© ØªØ®ØªØ§Ø± Ø£ÙØ¶Ù„ Ù…Ø²ÙˆØ¯ Ù…ØªØ§Ø­ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
                response = client.chat.completions.create(
                    model="", # ØªØ±Ùƒ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙØ§Ø±ØºØ§Ù‹ ÙŠØ­Ù„ Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ù€ ModelNotFoundError
                    messages=[{"role": "user", "content": prompt}]
                )
                
                st.markdown(f"### {content['result']}")
                st.write(response.choices[0].message.content)
                
            except Exception as e:
                st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„: {str(e)}")
    else:
        st.warning("ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª")